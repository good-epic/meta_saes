{
  "lambda2": [
    0.0,
    0.01,
    0.1,
    1.0
  ],
  "sigma_sq": [
    0.1
  ],
  "meta_dict_size": [
    1024
  ],
  "sae_type": [
    "batchtopk",
    "jumprelu"
  ],
  "match_architectures": true,
  "primary_sae_type": [
    "batchtopk",
    "jumprelu"
  ],
  "meta_sae_type": [
    "batchtopk",
    "jumprelu"
  ],
  "model_name": "gpt2-small",
  "dict_size": 12288,
  "primary_top_k": 64,
  "meta_top_k": 8,
  "bandwidth": 0.0001,
  "num_tokens": 100000000,
  "batch_size": 4096,
  "lr": 0.0003,
  "layer": 8,
  "site": "resid_pre",
  "dataset_path": "HuggingFaceFW/fineweb",
  "dataset_name": "sample-10BT",
  "n_primary_steps": 10,
  "n_meta_steps": 5,
  "num_batches_in_buffer_joint": 5,
  "num_batches_in_buffer_sequential": 3,
  "model_batch_size": 256,
  "seq_len": 128,
  "jumprelu_init_threshold": null,
  "target_l0": null
}